{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9c9345-6a4c-40ef-811e-2f9743da144f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.10.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp312-cp312-macosx_11_0_arm64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5b2e63f-e9df-4825-a257-b0ff33b4d4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask\n",
      "  Downloading dask-2024.10.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting click>=8.1 (from dask)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpickle>=3.0.0 (from dask)\n",
      "  Downloading cloudpickle-3.1.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /opt/miniconda3/envs/ML_Course/lib/python3.12/site-packages (from dask) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/ML_Course/lib/python3.12/site-packages (from dask) (24.1)\n",
      "Collecting partd>=1.4.0 (from dask)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/miniconda3/envs/ML_Course/lib/python3.12/site-packages (from dask) (6.0.1)\n",
      "Collecting toolz>=0.10.0 (from dask)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting locket (from partd>=1.4.0->dask)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Downloading dask-2024.10.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading cloudpickle-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: toolz, locket, cloudpickle, click, partd, dask\n",
      "Successfully installed click-8.1.7 cloudpickle-3.1.0 dask-2024.10.0 locket-1.0.0 partd-1.4.2 toolz-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724ed136-5c26-4281-8a9a-53548c629c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ML_Course/lib/python3.12/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import dask.dataframe as dd\n",
    "from rapidfuzz import process, fuzz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cfc9bb2-93bb-4d7b-8c8b-00c8ad39142a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.WRatio(\"this is a test\", \"this is a new test!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2bfc7b73-c12b-4b89-b64d-2ccca1abe697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio(\"this is a test\", \"this is a new test!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6c733f98-03c0-433e-a31a-2243c3b8d044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.88888888888889"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.WRatio(\"Love Song Taylor A\", \"Love Song (Taylor)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "22584636-caf0-4e37-8068-4d8b927537b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.48648648648648"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio(\"Love Song Taylor AA\", \"Love Song (Taylor)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a219c981-09bd-4e5b-8402-d50005b949fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.5"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.WRatio(\"Out of This World\", \"Always Running Out of Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a3abf8a9-ac01-4892-8bcd-7583b1d44d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15384615384615385"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "Levenshtein.normalized_similarity(\"Out of This World\", \"Always Running Out of Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "56afe841-3036-43dc-8249-81ea410d6f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18181818181818177"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "Levenshtein.normalized_similarity(\"Circus Music\", \"Exit Music (For A Dub)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222114f-492f-49a1-9508-afd63ed74b9d",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f0b83e-d77c-4a69-9130-e9a3636d6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load only necessary columns\n",
    "# df_opendb = pd.read_csv('/Users/anhnhat/Library/Mobile Documents/com~apple~CloudDocs/Documents/UNIMA/2. Semester Study/2. WS2425/4. W24 Web Data Integration/Project/Reduce Dataset/opendb_s.csv', usecols=['track_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38093da-bcde-429d-a6cb-24c13157584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_opendb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f46eda69-49e0-4591-8e0f-ae1f440d51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load only necessary columns\n",
    "# df_am = pd.read_csv('/Users/anhnhat/Library/Mobile Documents/com~apple~CloudDocs/Documents/UNIMA/2. Semester Study/2. WS2425/4. W24 Web Data Integration/Project/Reduce Dataset/apple_music_dataset.csv',usecols=['trackCensoredName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f1f2f4a-92b1-43ae-8111-944fdb9d146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load only necessary columns\n",
    "# df_am = pd.read_csv('/Users/anhnhat/Library/Mobile Documents/com~apple~CloudDocs/Documents/UNIMA/2. Semester Study/2. WS2425/4. W24 Web Data Integration/Project/Reduce Dataset/apple_music_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "973c15df-39d8-488c-9b43-b76b303432b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_am.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4ad2fd7-1ccc-49dd-99e7-43b9e6249779",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/anhnhat/Library/Mobile Documents/com~apple~CloudDocs/Documents/UNIMA/2. Semester Study/2. WS2425/4. W24 Web Data Integration/Project/Reduce Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a56267f3-4c38-4bfc-98ec-0a6da253b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                 Track\n",
      "0  A1                                 Music\n",
      "1  A2                                 Music\n",
      "2  A3  Don't Stop Believin' (2024 Remaster)\n",
      "3  A4                             I'm Yours\n",
      "4  A5                                 Music\n"
     ]
    }
   ],
   "source": [
    "# Apple music\n",
    "ids, tracks = [], []\n",
    "\n",
    "# Parse XML file iteratively\n",
    "for event, elem in ET.iterparse(path + 'apple.xml', events=('end',)):\n",
    "    if elem.tag == 'song':  # Look for each <song> element\n",
    "        # Extract ID and Track fields\n",
    "        id_value = elem.find('id').text if elem.find('id') is not None else None\n",
    "        track_value = elem.find('Track').text if elem.find('Track') is not None else None\n",
    "        \n",
    "        # Append extracted data to lists\n",
    "        ids.append(id_value)\n",
    "        tracks.append(track_value)\n",
    "\n",
    "        # Clear element to free memory\n",
    "        elem.clear()\n",
    "\n",
    "# Create DataFrame with the extracted columns\n",
    "df_am = pd.DataFrame({'ID': ids, 'Track': tracks})\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "print(df_am.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93f8520-2cec-4dc4-9adb-2955fb59adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_and_track(xml_file):\n",
    "    # Initialize lists to store the extracted data\n",
    "    ids, tracks = [], []\n",
    "\n",
    "    # Parse the XML file iteratively\n",
    "    for event, elem in ET.iterparse(path + xml_file, events=('end',)):\n",
    "        if elem.tag == 'song':  # Look for each <song> element\n",
    "            # Extract ID and Track fields\n",
    "            id_value = elem.find('id').text if elem.find('id') is not None else None\n",
    "            track_value = elem.find('Track').text if elem.find('Track') is not None else None\n",
    "            \n",
    "            # Append extracted data to lists\n",
    "            ids.append(id_value)\n",
    "            tracks.append(track_value)\n",
    "\n",
    "            # Clear element to free memory\n",
    "            elem.clear()\n",
    "\n",
    "    # Create DataFrame with the extracted columns\n",
    "    df = pd.DataFrame({'ID': ids, 'Track': tracks})\n",
    "\n",
    "    # Display the DataFrame to verify\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e866d30a-3f3a-4e89-9546-3d7d02cf6265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                 Track\n",
      "0  A1                                 Music\n",
      "1  A2                                 Music\n",
      "2  A3  Don't Stop Believin' (2024 Remaster)\n",
      "3  A4                             I'm Yours\n",
      "4  A5                                 Music\n"
     ]
    }
   ],
   "source": [
    "# Apple Music\n",
    "df_am = extract_id_and_track('apple.xml')\n",
    "print(df_am.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6214762-ded7-4d0a-a7e4-4ffa3de5b4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID            Track\n",
      "0  C1   Mr. Brightside\n",
      "1  C2       Wonderwall\n",
      "2  C3  Come as You Are\n",
      "3  C4      Take Me Out\n",
      "4  C5            Creep\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "df_million = extract_id_and_track('million.xml')\n",
    "print(df_million.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de744c8b-67dc-44b0-b6d9-21797e0536aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                            Track\n",
      "0  B1                                 Little Girl Blue\n",
      "1  B2                    Summertime blues (En directo)\n",
      "2  B3                 Man In Meridian (bossman Birdie)\n",
      "3  B4                           Better Man (feat. Reo)\n",
      "4  B5  You're All I Need To Get By (Glee Cast Version)\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "df_opendb= extract_id_and_track('opendb_s.xml')\n",
    "print(df_opendb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6737904-fa2e-4fe0-8f60-251455e47a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number rows of dataset Apple Music: 10000\n",
      "Number rows of dataset Millions: 50683\n",
      "Number rows of dataset Open DB: 100001\n"
     ]
    }
   ],
   "source": [
    "print('Number rows of dataset Apple Music: ' + str(df_am.shape[0]))\n",
    "print('Number rows of dataset Millions: ' + str(df_million.shape[0]))\n",
    "print('Number rows of dataset Open DB: ' + str(df_opendb.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "838d7d4a-cdbe-472b-8f5e-9c1cfd5d9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opendb_100k = df_opendb.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b475d32c-e2b2-4c80-8c22-b668bea05eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number rows of dataset Open DB random 100k: 100000\n"
     ]
    }
   ],
   "source": [
    "print('Number rows of dataset Open DB random 100k: ' + str(df_opendb_100k.shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e8ddc5d6-4a6f-49bb-90dc-3b5ce1ffce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_am = df_am.sample(n=2000)\n",
    "# df_million = df_million.sample(n=2000)\n",
    "# df_opendb_100k = df_opendb_100k.sample(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ae98ad70-278d-46ae-83b6-c80ecdf6c0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-10-30 23:55:49'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5a465146-de64-469d-ba81-cd1e827f4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_large_with_small(df_large, df_small, large_track_col='Track', small_track_col='Track', npartitions=10):\n",
    "    \"\"\"\n",
    "    Compare a large Dask DataFrame with a smaller Pandas DataFrame using RapidFuzz similarity metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        df_large (pd.DataFrame or dd.DataFrame): Large Dask DataFrame to compare.\n",
    "        df_small (pd.DataFrame): Smaller Pandas DataFrame for comparison.\n",
    "        large_track_col (str): Column name in df_large containing track names.\n",
    "        small_track_col (str): Column name in df_small containing track names.\n",
    "        npartitions (int): Number of partitions for Dask DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        dd.DataFrame: Dask DataFrame with similarity scores and matched track from df_small.\n",
    "    \"\"\"\n",
    "    # Convert large DataFrame to Dask if it's not already\n",
    "    if not isinstance(df_large, dd.DataFrame):\n",
    "        df_large = dd.from_pandas(df_large, npartitions=npartitions)\n",
    "\n",
    "    # Define the function to get the similarity score and matched track\n",
    "    def get_match_details(track):\n",
    "        best_match = process.extractOne(track, df_small[small_track_col], scorer=fuzz.WRatio)\n",
    "        score, matched_track = best_match[1], best_match[0] if best_match else (None, None)\n",
    "        return score, matched_track\n",
    "\n",
    "    # Apply the function and separate the results into two columns\n",
    "    df_large['match_details'] = df_large[large_track_col].apply(get_match_details, meta=(large_track_col, 'object'))\n",
    "    df_large = df_large.assign(\n",
    "        similarity_score=df_large['match_details'].apply(lambda x: x[0], meta=('x', 'float')),\n",
    "        matched_track=df_large['match_details'].apply(lambda x: x[1], meta=('x', 'object'))\n",
    "    )\n",
    "\n",
    "    # Drop the intermediate tuple column\n",
    "    df_large = df_large.drop(columns='match_details')\n",
    "\n",
    "    return df_large\n",
    "\n",
    "# Example usage\n",
    "# Compare large dataset with df_am\n",
    "df_result_am = compare_large_with_small(df_opendb_100k, df_am)\n",
    "df_result_am = df_result_am.compute()  # Convert back to Pandas if needed\n",
    "\n",
    "# Compare large dataset with million\n",
    "df_result_million = compare_large_with_small(df_opendb_100k,df_million )\n",
    "df_result_million = df_result_million.compute()  # Convert back to Pandas if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b6430e6e-5f8f-45ba-a431-47743365e84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Track</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>matched_track</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>B67</td>\n",
       "      <td>Replay (O meu time é a alegria da cidade)</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Replay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>B99</td>\n",
       "      <td>Replay</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Replay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>B288</td>\n",
       "      <td>Replay</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Replay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>B412</td>\n",
       "      <td>Replay (Sped Up Version) (feat. Ashley Jana)</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Replay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>B607</td>\n",
       "      <td>Circus Music</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                         Track  similarity_score  \\\n",
       "66    B67     Replay (O meu time é a alegria da cidade)              90.0   \n",
       "98    B99                                        Replay             100.0   \n",
       "287  B288                                        Replay             100.0   \n",
       "411  B412  Replay (Sped Up Version) (feat. Ashley Jana)              90.0   \n",
       "606  B607                                  Circus Music              90.0   \n",
       "\n",
       "    matched_track  \n",
       "66         Replay  \n",
       "98         Replay  \n",
       "287        Replay  \n",
       "411        Replay  \n",
       "606         Music  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_am.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9fae4c82-55b2-4cff-b8eb-3cea12546070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Track</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>matched_track</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>B67</td>\n",
       "      <td>Replay (O meu time é a alegria da cidade)</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>Ghost of a Chance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>B99</td>\n",
       "      <td>Replay</td>\n",
       "      <td>65.454545</td>\n",
       "      <td>Ready 2 Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>B288</td>\n",
       "      <td>Replay</td>\n",
       "      <td>65.454545</td>\n",
       "      <td>Ready 2 Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>B412</td>\n",
       "      <td>Replay (Sped Up Version) (feat. Ashley Jana)</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>Further On Up The Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>B607</td>\n",
       "      <td>Circus Music</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>Exit Music (For A Dub)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                         Track  similarity_score  \\\n",
       "66    B67     Replay (O meu time é a alegria da cidade)         85.500000   \n",
       "98    B99                                        Replay         65.454545   \n",
       "287  B288                                        Replay         65.454545   \n",
       "411  B412  Replay (Sped Up Version) (feat. Ashley Jana)         85.500000   \n",
       "606  B607                                  Circus Music         85.500000   \n",
       "\n",
       "              matched_track  \n",
       "66        Ghost of a Chance  \n",
       "98             Ready 2 Wear  \n",
       "287            Ready 2 Wear  \n",
       "411  Further On Up The Road  \n",
       "606  Exit Music (For A Dub)  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_million.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "467c15bd-e152-4a46-89bb-3c56dbdb4923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the results are in Pandas format\n",
    "df_result_am = df_result_am.compute() if isinstance(df_result_am, dd.DataFrame) else df_result_am\n",
    "df_result_million = df_result_million.compute() if isinstance(df_result_million, dd.DataFrame) else df_result_million\n",
    "\n",
    "# Write each DataFrame to CSV\n",
    "df_result_am.to_csv('df_result_am.csv', index=False)\n",
    "df_result_million.to_csv('df_result_million.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c920aefd-27da-4745-83b7-888e879eef54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-10-31 00:20:33'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011d768-f1b5-4d34-a6f9-7ec93facb9ed",
   "metadata": {},
   "source": [
    "### normalized Levenshtein similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dede990b-ac18-4370-bf1a-8db1bbf92381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2024-10-31 16:39:21.887359\n",
      "End Time: 2024-10-31 16:49:47.338898\n",
      "Runtime: 0:10:25.451539\n",
      "Results saved to df_result_am.csv\n",
      "Start Time: 2024-10-31 16:49:47.482583\n",
      "End Time: 2024-10-31 17:15:37.998957\n",
      "Runtime: 0:25:50.516374\n",
      "Results saved to df_result_million.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from rapidfuzz import process\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "from datetime import datetime\n",
    "\n",
    "def compare_large_with_small(df_large, df_small, output_file, large_track_col='Track', small_track_col='Track', npartitions=10, score_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Compare a large Dask DataFrame with a smaller Pandas DataFrame using Levenshtein normalized similarity with a score threshold,\n",
    "    track runtime, and save results to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        df_large (pd.DataFrame or dd.DataFrame): Large Dask DataFrame to compare.\n",
    "        df_small (pd.DataFrame): Smaller Pandas DataFrame for comparison.\n",
    "        output_file (str): Name of the output CSV file.\n",
    "        large_track_col (str): Column name in df_large containing track names.\n",
    "        small_track_col (str): Column name in df_small containing track names.\n",
    "        npartitions (int): Number of partitions for Dask DataFrame.\n",
    "        score_threshold (float): Minimum similarity score to consider a match, between 0 and 1.\n",
    "        \n",
    "    Returns:\n",
    "        dd.DataFrame: Dask DataFrame with similarity scores, matched track, and matched ID from df_small.\n",
    "    \"\"\"\n",
    "    # Record start time\n",
    "    start_time = datetime.now()\n",
    "    print(f\"Start Time: {start_time}\")\n",
    "\n",
    "    # Convert large DataFrame to Dask if it's not already\n",
    "    if not isinstance(df_large, dd.DataFrame):\n",
    "        df_large = dd.from_pandas(df_large, npartitions=npartitions)\n",
    "\n",
    "    # Define the function to get the normalized Levenshtein similarity score, matched track, and matched ID\n",
    "    def get_match_details(track):\n",
    "        best_match = process.extractOne(\n",
    "            track,\n",
    "            df_small[small_track_col],\n",
    "            scorer=Levenshtein.normalized_similarity\n",
    "            #score_cutoff=score_threshold  # Apply the score threshold\n",
    "        )\n",
    "        if best_match:\n",
    "            score, matched_track = best_match[1], best_match[0]\n",
    "            matched_id = df_small[df_small[small_track_col] == matched_track][\"ID\"].values[0]\n",
    "        else:\n",
    "            score, matched_track, matched_id = None, None, None\n",
    "        return score, matched_track, matched_id\n",
    "\n",
    "    # Apply the function and separate the results into three columns\n",
    "    df_large['match_details'] = df_large[large_track_col].apply(get_match_details, meta=(large_track_col, 'object'))\n",
    "    df_large = df_large.assign(\n",
    "        similarity_score=df_large['match_details'].apply(lambda x: x[0], meta=('x', 'float')),\n",
    "        matched_track=df_large['match_details'].apply(lambda x: x[1], meta=('x', 'object')),\n",
    "        matched_id=df_large['match_details'].apply(lambda x: x[2], meta=('x', 'object'))\n",
    "    )\n",
    "\n",
    "    # Drop the intermediate tuple column\n",
    "    df_large = df_large.drop(columns='match_details')\n",
    "\n",
    "    # Compute the Dask DataFrame to get the result in Pandas format\n",
    "    df_result = df_large.compute()\n",
    "\n",
    "    # Record end time\n",
    "    end_time = datetime.now()\n",
    "    print(f\"End Time: {end_time}\")\n",
    "\n",
    "    # Calculate and print runtime\n",
    "    runtime = end_time - start_time\n",
    "    print(f\"Runtime: {runtime}\")\n",
    "\n",
    "    # Write the result to CSV\n",
    "    df_result.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    return df_result\n",
    "\n",
    "# Example usage\n",
    "# Compare large dataset with df_am and save results to CSV with score threshold of 0.6\n",
    "#df_result_am = compare_large_with_small(df_opendb, df_am, 'df_result_am.csv', score_threshold=0.6)\n",
    "df_result_am = compare_large_with_small(df_opendb, df_am, 'df_result_am.csv')\n",
    "\n",
    "# Compare large dataset with df_million and save results to CSV with score threshold of 0.6\n",
    "#df_result_million = compare_large_with_small(df_opendb, df_million, 'df_result_million.csv', score_threshold=0.6)\n",
    "df_result_million = compare_large_with_small(df_opendb, df_million, 'df_result_million.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db347a-450d-4b96-bff3-d633ce5ab93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2024-10-31 16:09:59.123551\n",
      "End Time: 2024-10-31 16:14:31.133282\n",
      "Runtime: 0:04:32.009731\n",
      "Results saved to df_result_am.csv\n",
      "Start Time: 2024-10-31 16:14:31.272288\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m df_result_am \u001b[38;5;241m=\u001b[39m compare_large_with_small_noscore(df_opendb, df_am, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_result_am.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Compare large dataset with df_million and save results to CSV with score threshold of 0.6\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m df_result_million \u001b[38;5;241m=\u001b[39m compare_large_with_small_noscore(df_opendb, df_million, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_result_million.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 63\u001b[0m, in \u001b[0;36mcompare_large_with_small_noscore\u001b[0;34m(df_large, df_small, output_file, large_track_col, small_track_col, large_id_col, small_id_col, npartitions, score_threshold)\u001b[0m\n\u001b[1;32m     60\u001b[0m df_large[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlarge_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_large[large_id_col]\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Compute the Dask DataFrame to get the result in Pandas format\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m df_result \u001b[38;5;241m=\u001b[39m df_large\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Record end time\u001b[39;00m\n\u001b[1;32m     66\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ML_Course/lib/python3.12/site-packages/dask/base.py:372\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ML_Course/lib/python3.12/site-packages/dask/base.py:660\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 660\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ML_Course/lib/python3.12/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ML_Course/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from rapidfuzz import process\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "from datetime import datetime\n",
    "\n",
    "def compare_large_with_small_noscore(df_large, df_small, output_file, large_track_col='Track', small_track_col='Track', large_id_col='ID', small_id_col='ID', npartitions=10, score_threshold=0.6):\n",
    "    \"\"\"\n",
    "    Compare a large Dask DataFrame with a smaller Pandas DataFrame using Levenshtein normalized similarity with a score threshold,\n",
    "    track runtime, and save results to a CSV file, including IDs from both DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "        df_large (pd.DataFrame or dd.DataFrame): Large Dask DataFrame to compare.\n",
    "        df_small (pd.DataFrame): Smaller Pandas DataFrame for comparison.\n",
    "        output_file (str): Name of the output CSV file.\n",
    "        large_track_col (str): Column name in df_large containing track names.\n",
    "        small_track_col (str): Column name in df_small containing track names.\n",
    "        large_id_col (str): Column name in df_large containing IDs.\n",
    "        small_id_col (str): Column name in df_small containing IDs.\n",
    "        npartitions (int): Number of partitions for Dask DataFrame.\n",
    "        score_threshold (float): Minimum similarity score to consider a match, between 0 and 1.\n",
    "        \n",
    "    Returns:\n",
    "        dd.DataFrame: Dask DataFrame with similarity scores and matched track from df_small.\n",
    "    \"\"\"\n",
    "    # Record start time\n",
    "    start_time = datetime.now()\n",
    "    print(f\"Start Time: {start_time}\")\n",
    "\n",
    "    # Convert large DataFrame to Dask if it's not already\n",
    "    if not isinstance(df_large, dd.DataFrame):\n",
    "        df_large = dd.from_pandas(df_large, npartitions=npartitions)\n",
    "\n",
    "    # Define the function to get the normalized Levenshtein similarity score, matched track, and matched ID\n",
    "    def get_match_details(row):\n",
    "        track = row[large_track_col]\n",
    "        best_match = process.extractOne(\n",
    "            track,\n",
    "            df_small[[small_track_col, small_id_col]].values.tolist(),\n",
    "            scorer=Levenshtein.normalized_similarity,\n",
    "            processor=lambda x: x[0]  # Extract the track name for similarity matching\n",
    "        )\n",
    "        if best_match:\n",
    "            score = best_match[1]\n",
    "            matched_track, matched_id = best_match[0]\n",
    "        else:\n",
    "            score, matched_track, matched_id = None, None, None\n",
    "        return score, matched_track, matched_id\n",
    "\n",
    "    # Apply the function and separate the results into multiple columns\n",
    "    df_large['match_details'] = df_large.apply(get_match_details, axis=1, meta=(large_track_col, 'object'))\n",
    "    df_large = df_large.assign(\n",
    "        similarity_score=df_large['match_details'].apply(lambda x: x[0], meta=('x', 'float')),\n",
    "        matched_track=df_large['match_details'].apply(lambda x: x[1], meta=('x', 'object')),\n",
    "        matched_id=df_large['match_details'].apply(lambda x: x[2], meta=('x', 'object'))\n",
    "    )\n",
    "\n",
    "    # Drop the intermediate tuple column and include original ID from the large DataFrame\n",
    "    df_large = df_large.drop(columns='match_details')\n",
    "    df_large['large_id'] = df_large[large_id_col]\n",
    "\n",
    "    # Compute the Dask DataFrame to get the result in Pandas format\n",
    "    df_result = df_large.compute()\n",
    "\n",
    "    # Record end time\n",
    "    end_time = datetime.now()\n",
    "    print(f\"End Time: {end_time}\")\n",
    "\n",
    "    # Calculate and print runtime\n",
    "    runtime = end_time - start_time\n",
    "    print(f\"Runtime: {runtime}\")\n",
    "\n",
    "    # Write the result to CSV\n",
    "    df_result.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "    return df_result\n",
    "\n",
    "# Example usage\n",
    "# Compare large dataset with df_am and save results to CSV with score threshold of 0.6\n",
    "#df_result_am = compare_large_with_small(df_opendb, df_am, 'df_result_am.csv', score_threshold=0.6)\n",
    "df_result_am = compare_large_with_small_noscore(df_opendb, df_am, 'df_result_am.csv')\n",
    "\n",
    "# Compare large dataset with df_million and save results to CSV with score threshold of 0.6\n",
    "df_result_million = compare_large_with_small_noscore(df_opendb, df_million, 'df_result_million.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "684add8e-37c5-4405-82bf-f7e574254754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance: 15\n",
      "Normalized Similarity: 0.0625\n"
     ]
    }
   ],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "\n",
    "# Define the two strings\n",
    "string1 = \"Little Girl Blue\"\n",
    "string2 = \"L\"\n",
    "\n",
    "# Calculate the Levenshtein distance and normalized similarity\n",
    "distance = Levenshtein.distance(string1, string2)\n",
    "normalized_similarity = Levenshtein.normalized_similarity(string1, string2)\n",
    "\n",
    "print(\"Levenshtein Distance:\", distance)\n",
    "print(\"Normalized Similarity:\", normalized_similarity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
